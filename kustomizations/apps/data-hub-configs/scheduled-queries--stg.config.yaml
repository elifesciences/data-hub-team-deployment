scheduledQueries:
  - dataPipelineId: create_ga4_page_views_by_page_and_date
    bigQuery:
      projectName: 'elife-data-pipeline'
      sqlQuery: |-
        CREATE TABLE IF NOT EXISTS elife-data-pipeline.{ENV}.ga4_page_views_by_page_and_date (
          page_location STRING,
          event_date DATE,
          unique_page_views INT64,
          page_views INT64
        )
        PARTITION BY event_date

  - dataPipelineId: update_ga4_page_views_by_page_and_date
    state:
      initialState:
        startDate: '2022-05-24'
      stateFile:
        bucketName: '{ENV}-elife-data-pipeline'
        objectName: 'airflow-config/scheduled-queries/{ENV}-ga4_page_views_by_page_and_date-state.json'
    bigQuery:
      projectName: 'elife-data-pipeline'
      sqlQuery: |-
        MERGE INTO `elife-data-pipeline.{ENV}.ga4_page_views_by_page_and_date` AS target
        USING (
          WITH t_ga4_event AS (
            SELECT 
              event_name,
              PARSE_DATE(r'%Y%m%d', REGEXP_EXTRACT(event._TABLE_SUFFIX, r'(2\d+)$')) AS event_date,
              event._TABLE_SUFFIX AS table_suffix,
              page_location_event_param.value.string_value AS page_location,
              CAST(ga_session_id_event_param.value.int_value AS STRING) AS ga_session_id,  
              debug_mode_event_param.value.int_value AS debug_mode,
              (debug_mode_event_param.value.int_value IS NOT NULL) AS is_debug_mode
            FROM `elife-data-pipeline.analytics_316514145.events_*` AS event
            LEFT JOIN UNNEST(event.event_params) AS page_location_event_param
              ON page_location_event_param.key = 'page_location'
            LEFT JOIN UNNEST(event.event_params) AS ga_session_id_event_param
              ON ga_session_id_event_param.key = 'ga_session_id'
            LEFT JOIN UNNEST(event.event_params) AS debug_mode_event_param
              ON debug_mode_event_param.key = 'debug_mode'
            WHERE event_name IN ('page_view')
              AND event._TABLE_SUFFIX >= FORMAT_DATE('%Y%m%d', DATE_SUB(DATE('{start_date}'), INTERVAL 3 DAY))
          )
          SELECT
            page_location,
            event_date,
            COUNT(DISTINCT ga_session_id) AS unique_page_views,
            COUNT(*) AS page_views
          FROM t_ga4_event
          WHERE NOT is_debug_mode
            AND ga_session_id IS NOT NULL
          GROUP BY page_location, event_date
        ) AS source
        ON target.page_location = source.page_location
          AND target.event_date = source.event_date
        WHEN MATCHED THEN
          UPDATE SET
            unique_page_views = source.unique_page_views,
            page_views = source.page_views
        WHEN NOT MATCHED THEN
          INSERT (page_location, event_date, unique_page_views, page_views)
          VALUES (source.page_location, source.event_date, source.unique_page_views, source.page_views)

  - dataPipelineId: remove_old_manuscript_version_all_records
    bigQuery:
      projectName: 'elife-data-pipeline'
      sqlQuery: |-
        DELETE FROM `elife-data-pipeline.{ENV}.manuscript_version_all` AS t_delete
        WHERE EXISTS (
          SELECT 1
          FROM (
            SELECT
              key,
              MAX(imported_timestamp) AS latest_imported_timestamp
            FROM (
              SELECT
                TO_JSON_STRING((SELECT AS STRUCT t_data.* EXCEPT(provenance, modified_timestamp, stages, emails, abstract))) AS key,
                provenance.imported_timestamp,
              FROM `elife-data-pipeline.{ENV}.manuscript_version_all` AS t_data
            )
            GROUP BY key
          ) AS t_source
          WHERE TO_JSON_STRING((SELECT AS STRUCT t_delete.* EXCEPT(provenance, modified_timestamp, stages, emails, abstract))) = t_source.key
            AND t_delete.provenance.imported_timestamp < t_source.latest_imported_timestamp
        )

  - dataPipelineId: remove_old_person_all_records
    bigQuery:
      projectName: 'elife-data-pipeline'
      sqlQuery: |-
        DELETE FROM `elife-data-pipeline.{ENV}.person_all` AS t_delete
        WHERE EXISTS (
          SELECT 1
          FROM (
            SELECT
              key,
              MAX(imported_timestamp) AS latest_imported_timestamp
            FROM (
              SELECT
                TO_JSON_STRING((SELECT AS STRUCT t_data.* EXCEPT(provenance, modified_timestamp))) AS key,
                provenance.imported_timestamp,
              FROM `elife-data-pipeline.{ENV}.person_all` AS t_data
            )
            GROUP BY key
          ) AS t_source
          WHERE TO_JSON_STRING((SELECT AS STRUCT t_delete.* EXCEPT(provenance, modified_timestamp))) = t_source.key
            AND t_delete.provenance.imported_timestamp < t_source.latest_imported_timestamp
        )

  - dataPipelineId: remove_old_489_datascience_editor_keywords_records
    bigQuery:
      projectName: 'elife-data-pipeline'
      sqlQuery: |-
        DELETE FROM `elife-data-pipeline.{ENV}.489_datascience_editor_keywords` AS t_delete
        WHERE EXISTS (
          SELECT 1
          FROM (
            SELECT
              key,
              MAX(imported_timestamp) AS latest_imported_timestamp
            FROM (
              SELECT
                TO_JSON_STRING((SELECT AS STRUCT t_data.* EXCEPT(provenance, imported_timestamp, date_generated, date_generated_info))) AS key,
                imported_timestamp,
              FROM `elife-data-pipeline.{ENV}.489_datascience_editor_keywords` AS t_data
            )
            GROUP BY key
          ) AS t_source
          WHERE TO_JSON_STRING((SELECT AS STRUCT t_delete.* EXCEPT(provenance, imported_timestamp, date_generated, date_generated_info))) = t_source.key
            AND t_delete.imported_timestamp < t_source.latest_imported_timestamp
        )

  - dataPipelineId: remove_old_editorial_manuscript_consultation_session
    bigQuery:
      projectName: 'elife-data-pipeline'
      sqlQuery: |-
        DELETE FROM `elife-data-pipeline.{ENV}.editorial_manuscript_consultation_session` AS t_delete
        WHERE EXISTS (
          SELECT 1
          FROM (
            SELECT
              key,
              MAX(imported_timestamp) AS latest_imported_timestamp
            FROM (
              SELECT
                TO_JSON_STRING((SELECT AS STRUCT t_data.* EXCEPT(provenance, imported_timestamp, date_generated_info))) AS key,
                imported_timestamp,
              FROM `elife-data-pipeline.{ENV}.editorial_manuscript_consultation_session` AS t_data
            )
            GROUP BY key
          ) AS t_source
          WHERE TO_JSON_STRING((SELECT AS STRUCT t_delete.* EXCEPT(provenance, imported_timestamp, date_generated_info))) = t_source.key
            AND t_delete.imported_timestamp < t_source.latest_imported_timestamp
        )

  - dataPipelineId: remove_old_gmail_thread_details_records
    bigQuery:
      projectName: 'elife-data-pipeline'
      sqlQuery: |-
        DELETE FROM `elife-data-pipeline.{ENV}.gmail_thread_details` AS t_delete
        WHERE EXISTS (
          SELECT 1
          FROM (
            SELECT
              key,
              MAX(imported_timestamp) AS latest_imported_timestamp
            FROM (
              SELECT
                TO_JSON_STRING(STRUCT(user_id, threadId)) AS key,
                imported_timestamp,
              FROM `elife-data-pipeline.{ENV}.gmail_thread_details` AS t_data
            )
            GROUP BY key
          ) AS t_source
          WHERE TO_JSON_STRING(STRUCT(t_delete.user_id, t_delete.threadId)) = t_source.key
            AND t_delete.imported_timestamp < t_source.latest_imported_timestamp
        )
